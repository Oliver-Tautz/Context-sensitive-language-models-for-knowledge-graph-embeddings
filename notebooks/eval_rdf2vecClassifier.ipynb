{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edae41f5-8379-478a-80b4-8703c94916fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../code')\n",
    "\n",
    "from settings import VECTOR_SIZE,  CLASSIFIER_EPOCHS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97199e0-c550-49f1-a095-5ef70d0497d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "word_vectors = Word2Vec.load('walks/model').wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0810bf13-53a4-4829-b1af-6137f2e2029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 15:16:39.136467: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-17 15:16:39.136488: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found trained model! Loading :)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from models import ClassifierSimple\n",
    "import torch\n",
    "model = ClassifierSimple()    \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if Path('rdf2vecClassfier.pth').is_file():\n",
    "    print('found trained model! Loading :)')\n",
    "    model.load_state_dict(torch.load('rdf2vecClassfier.pth'))\n",
    "    history = pd.read_csv('log.csv')\n",
    "    model = model.to(device)\n",
    "else:\n",
    "    print('model not found. Train it with ''train_rdf2vec_classifier.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c23be91-0434-4bcb-a209-1f3a0ca8a03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 2 triples from training set\n",
      "removed 2 triples from validation set\n",
      "removed 0 triples from test set\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_multidigraph\n",
    "from utils_graph import clean_graph, get_entities\n",
    "\n",
    "\n",
    "g_train = Graph()\n",
    "g_val = Graph()\n",
    "g_test = Graph()\n",
    "\n",
    "g_train = g_train.parse('FB15k-237/train_1000.nt', format='nt')\n",
    "g_val   = g_val.parse('FB15k-237/valid_1000.nt', format='nt')\n",
    "g_test  = g_test.parse('FB15k-237/test_1000.nt', format='nt')\n",
    "\n",
    "\n",
    "# clean graphs \n",
    "# number of triples removed should be low, a few hundred\n",
    "print(f\"removed {clean_graph(g_train,word_vectors)} triples from training set\")\n",
    "print(f\"removed {clean_graph(g_val,word_vectors)} triples from validation set\")\n",
    "print(f\"removed {clean_graph(g_test,word_vectors)} triples from test set\")\n",
    "\n",
    "entities = get_entities((g_train,g_val,g_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72176004-0f5e-4db3-b76c-6defc6512dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_eval import eval_ranks, mean_rank, mean_reciprocal_rank, hitsAt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b6dcba-40c6-4c16-a9c1-3ba95c7e06e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 156/156 [02:57<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MR: 62.0576171875\n",
      "MRR: 0.2724679112434387\n",
      "H@1: 0.08667334914207458\n",
      "H@3: 0.17284569144248962\n",
      "H@10: 0.33717435598373413\n",
      "MR_head: 49.41482925415039\n",
      "MRR_head: 0.35735464096069336\n",
      "H@1_head: 0.12324649095535278\n",
      "H@3_head: 0.22545090317726135\n",
      "H@10_head: 0.4008015990257263\n",
      "MR_tail: 74.70040130615234\n",
      "MRR_tail: 0.18758118152618408\n",
      "H@1_tail: 0.05010019987821579\n",
      "H@3_tail: 0.1202404797077179\n",
      "H@10_tail: 0.27354708313941956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'preprocessing': 4.458399113998894,\n",
       " 'subgraph': 0.15552735196979484,\n",
       " 'collect_embeddings': 0.006837044002168113,\n",
       " 'copy embeddings into array': 16.40838050302409,\n",
       " 'score_embeddings': 160.23794436401295,\n",
       " 'rank_embeddings': 0.3474007089898805}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tested scoring on cpu\n",
    "import gc\n",
    "torch.set_num_threads(32)\n",
    "with torch.no_grad():\n",
    "    head_ranks, tail_ranks,pt = eval_ranks(model,g_train,lambda x: word_vectors[x],force_cpu=True,filtered=True,bit16tensors=False)\n",
    "    \n",
    "    print(f\"MR: {mean_rank(head_ranks, tail_ranks)}\")\n",
    "    print(f\"MRR: {mean_reciprocal_rank(head_ranks, tail_ranks)}\")\n",
    "    \n",
    "    print(f\"H@1: {hitsAt(head_ranks, tail_ranks,1)}\")\n",
    "    print(f\"H@3: {hitsAt(head_ranks, tail_ranks,3)}\")\n",
    "    print(f\"H@10: {hitsAt(head_ranks, tail_ranks,10)}\")\n",
    "    \n",
    "    \n",
    "    print(f\"MR_head: {torch.mean(head_ranks)}\")\n",
    "    print(f\"MRR_head: {torch.mean(1/head_ranks)}\")\n",
    "    \n",
    "    print(f\"H@1_head: {(head_ranks <= 1).sum()/len(tail_ranks)}\")\n",
    "    print(f\"H@3_head: {(head_ranks <= 3).sum()/len(tail_ranks)}\")\n",
    "    print(f\"H@10_head: {(head_ranks <= 10).sum()/len(tail_ranks)}\")\n",
    "    \n",
    "    \n",
    "    print(f\"MR_tail: {torch.mean(tail_ranks)}\")\n",
    "    print(f\"MRR_tail: {torch.mean(1/tail_ranks)}\")\n",
    "    \n",
    "    print(f\"H@1_tail: {(tail_ranks <= 1).sum()/len(tail_ranks)}\")\n",
    "    print(f\"H@3_tail: {(tail_ranks <= 3).sum()/len(tail_ranks)}\")\n",
    "    print(f\"H@10_tail: {(tail_ranks <= 10).sum()/len(tail_ranks)}\")\n",
    "    \n",
    "    \n",
    "gc.collect()\n",
    "pt.stats_sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aab68c-6928-4c92-98a6-e0d716cf90b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('here!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "std-env",
   "language": "python",
   "name": "std-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
