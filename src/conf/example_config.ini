[TRAIN]

# PATH to train graph in N-Triples format
DATASET_PATH = ./FB15K-237_train.nt

# Path to file containing relevant entities. Leave blank for no filterfile
DATASET_PATH_FILTERFILE = ./FB15K-237_relevant_entities.txt

# Vector Size used by all models. BERT default is 128
VECTOR_SIZE=200

# max epochs to train Bert
BERT_EPOCHS = 150

# BERT classifier head Dropout.
BERT_CLASSIFIER_DROPOUT = 0.25

# New model Huggingface name
# also working folder name.
BERT_NAME = tiny_bert_from_scratch_simple_datamining

# Use different dataset type to train
# One of MWM, NTP, LP
BERT_DATASET_TYPE = MWM


# Batchsize for bert. 
BERT_BATCHSIZE=1000

#Sets train/test size very small and uses tiny-bert for testing.
DEBUG = False

# Train Bert with rdf2vec walks on MWM. Choose parameters.
# Does nothing for NTP and LP

BERT_WALK_USE = True
BERT_WALK_DEPTH = 4
BERT_WALK_COUNT = 100
BERT_WALK_GENERATION_MODE = RANDOM_WALKS


# Number of epochs to wait before stopping.
# Set negative for no early stopping. 
BERT_EARLY_STOPPING_PATIENCE = -10

# Minimum val loss difference that is considered better
BERT_EARLY_STOPPING_DELTA = 0.005

# MWM mask chance
BERT_MASK_CHANCE=0.33

# MWM mask token chance
BERT_MASK_TOKEN_CHANCE=1

# jRDF2Vec thread count.
WALK_THREAD_COUNT=10
